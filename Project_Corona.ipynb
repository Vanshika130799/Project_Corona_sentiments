{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Corona tweets.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb4af5fc"
      },
      "source": [
        "from pyspark.sql.types import\n",
        "from pyspark.sql.functions import \n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession \n",
        "from pyspark import SparkContext \n",
        "from pyspark.sql import SQLContext \n",
        "\n",
        "from pyspark.ml.feature import Tokenizer \n",
        "from pyspark.ml.feature import CountVectorizer \n",
        "from pyspark.ml import Pipeline \n",
        "from pyspark.ml.classification import RandomForestClassifier \n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
        "\n",
        "conf = pyspark.SparkConf().setAll([('spark.executor.memory', '16g'), ('spark.executor.cores', '1'), ('spark.cores.max', '1'), ('spark.driver.memory','16g')])\n",
        "sc = SparkContext.getOrCreate(conf = conf) \n",
        "sqlContext = SQLContext.getOrCreate(sc) \n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate() "
      ],
      "id": "eb4af5fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b128252",
        "outputId": "a4fba909-7f05-4c1c-bf43-55f9a798535e"
      },
      "source": [
        "file_path=\"Corona_NLP_train.csv\"\n",
        "\n",
        "tweets= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(file_path)\n",
        "tweets.show()\n"
      ],
      "id": "1b128252",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
            "|            UserName|          ScreenName|            Location|             TweetAt|       OriginalTweet|Sentiment|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
            "|                3799|               48751|              London|          16-03-2020|@MeNyrbie @Phil_G...|  Neutral|\n",
            "|                3800|               48752|                  UK|          16-03-2020|advice Talk to yo...| Positive|\n",
            "|                3801|               48753|           Vagabonds|          16-03-2020|Coronavirus Austr...| Positive|\n",
            "|                3802|               48754|                null|          16-03-2020|My food stock is ...|     null|\n",
            "|              PLEASE|         don't panic| THERE WILL BE EN...|                null|                null|     null|\n",
            "|           Stay calm|          stay safe.|                null|                null|                null|     null|\n",
            "|#COVID19france #C...|            Positive|                null|                null|                null|     null|\n",
            "|                3803|               48755|                null|          16-03-2020|Me, ready to go a...|     null|\n",
            "|Not because I'm p...| but because my f...|          but please| don't panic. It ...|                null|     null|\n",
            "|#CoronavirusFranc...|  Extremely Negative|                null|                null|                null|     null|\n",
            "|                3804|               48756|ÜT: 36.319708,-82...|          16-03-2020|As news of the re...| Positive|\n",
            "|                3805|               48757|35.926541,-78.753267|          16-03-2020|\"Cashier at groce...| Positive|\n",
            "|                3806|               48758|             Austria|          16-03-2020|Was at the superm...|     null|\n",
            "|#toiletpapercrisi...|             Neutral|                null|                null|                null|     null|\n",
            "|                3807|               48759|     Atlanta, GA USA|          16-03-2020|Due to COVID-19 o...| Positive|\n",
            "|                3808|               48760|    BHAVNAGAR,GUJRAT|          16-03-2020|For corona preven...| Negative|\n",
            "|                3809|               48761|      Makati, Manila|          16-03-2020|All month there h...|  Neutral|\n",
            "|                3810|               48762|Pitt Meadows, BC,...|          16-03-2020|Due to the Covid-...|     null|\n",
            "|The wait time may...| particularly bee...|                null|                null|                null|     null|\n",
            "|We thank you for ...|  Extremely Positive|                null|                null|                null|     null|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f738c58b",
        "outputId": "18d51ddc-7d9a-4cbd-c113-618e21e12a44"
      },
      "source": [
        "tweets.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in tweets.columns]).show() #Check for null values"
      ],
      "id": "f738c58b",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+----------+--------+-------+-------------+---------+\n",
            "|UserName|ScreenName|Location|TweetAt|OriginalTweet|Sentiment|\n",
            "+--------+----------+--------+-------+-------------+---------+\n",
            "|       4|     12417|   33799|  26311|        26663|    39429|\n",
            "+--------+----------+--------+-------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbd60188"
      },
      "source": [
        "tweets=tweets.na.drop(how=\"any\")"
      ],
      "id": "cbd60188",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c832945c",
        "outputId": "f08892a1-5d9d-4590-83fc-a0f38149751c"
      },
      "source": [
        "tweets.show()"
      ],
      "id": "c832945c",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+----------+--------------------+----------+--------------------+------------------+\n",
            "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|\n",
            "+--------+----------+--------------------+----------+--------------------+------------------+\n",
            "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|\n",
            "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|\n",
            "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|\n",
            "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|\n",
            "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|\n",
            "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|\n",
            "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|\n",
            "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|\n",
            "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|\n",
            "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|\n",
            "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|\n",
            "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|\n",
            "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|\n",
            "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|\n",
            "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|\n",
            "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|\n",
            "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|\n",
            "|    3838|     48790|       United States|16-03-2020|Now I can go to t...|          Positive|\n",
            "|    3841|     48793|             Houston|16-03-2020|CHECK VIDEO ?? ht...|Extremely Negative|\n",
            "|    3842|     48794|Vancouver, Britis...|16-03-2020|Breaking Story: O...|           Neutral|\n",
            "+--------+----------+--------------------+----------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b83e762b"
      },
      "source": [
        "# from pyspark.ml.feature import StringIndexer\n",
        "# indexers = [StringIndexer(inputCol=\"Sentiment\", outputCol=\"Target\").fit(df)]"
      ],
      "id": "b83e762b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6364b10f"
      },
      "source": [
        "# pipeline = Pipeline(stages=indexers)\n",
        "# df_r = pipeline.fit(tweets).transform(tweets)"
      ],
      "id": "6364b10f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e18664a"
      },
      "source": [
        "# df_r.show()"
      ],
      "id": "3e18664a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3268347d"
      },
      "source": [
        "#decode_map = {0: \"Neutral\", 1: \"Positive\",1:\"Extremely Positive\",2:\"Extremely Negative\",2:\"Negative\"}\n",
        "#maping the column with particular data\n",
        "\n",
        "def decode_sentiment(label):\n",
        "    if label == \"Positive\" or label == \"Extremely Positive\":\n",
        "        return \"Positive\"\n",
        "    elif label == \"Negative\" or label == \"Extremely Negative\":\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\""
      ],
      "id": "3268347d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6100564"
      },
      "source": [
        "stringNumber = udf(lambda m: decode_sentiment(m))"
      ],
      "id": "c6100564",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df3017a2"
      },
      "source": [
        "# tweets.select('Sentiment').distinct().collect()\n"
      ],
      "id": "df3017a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b2109c9"
      },
      "source": [
        "tweets=tweets.withColumn(\"target_Sentiment\", stringNumber(\"Sentiment\"))\n"
      ],
      "id": "6b2109c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65aa1921",
        "outputId": "23cea961-c555-4e0f-fb35-18cda4e99d27"
      },
      "source": [
        "tweets.show(2)"
      ],
      "id": "65aa1921",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+----------+--------+----------+--------------------+---------+----------------+\n",
            "|UserName|ScreenName|Location|   TweetAt|       OriginalTweet|Sentiment|target_Sentiment|\n",
            "+--------+----------+--------+----------+--------------------+---------+----------------+\n",
            "|    3799|     48751|  London|16-03-2020|@MeNyrbie @Phil_G...|  Neutral|         Neutral|\n",
            "|    3800|     48752|      UK|16-03-2020|advice Talk to yo...| Positive|        Positive|\n",
            "+--------+----------+--------+----------+--------------------+---------+----------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8f225a"
      },
      "source": [
        "drop_list =[\"UserName\",\"ScreenName\",\"Location\",\"TweetAt\",\"Sentiment\"]\n",
        "data = tweets.select([column for column in tweets.columns if column not in drop_list])"
      ],
      "id": "8a8f225a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d412d3e",
        "outputId": "4523909f-655f-4733-9a63-bd44cdcfaea7"
      },
      "source": [
        "data.show()"
      ],
      "id": "1d412d3e",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+----------------+\n",
            "|       OriginalTweet|target_Sentiment|\n",
            "+--------------------+----------------+\n",
            "|@MeNyrbie @Phil_G...|         Neutral|\n",
            "|advice Talk to yo...|        Positive|\n",
            "|Coronavirus Austr...|        Positive|\n",
            "|As news of the re...|        Positive|\n",
            "|\"Cashier at groce...|        Positive|\n",
            "|Due to COVID-19 o...|        Positive|\n",
            "|For corona preven...|        Negative|\n",
            "|All month there h...|         Neutral|\n",
            "|#horningsea is a ...|        Positive|\n",
            "|For those who are...|        Positive|\n",
            "|with 100  nations...|        Negative|\n",
            "|@10DowningStreet ...|        Negative|\n",
            "|UK #consumer poll...|        Positive|\n",
            "|In preparation fo...|        Negative|\n",
            "|This morning I te...|        Negative|\n",
            "|Went to the super...|         Neutral|\n",
            "|Worried about the...|        Positive|\n",
            "|Now I can go to t...|        Positive|\n",
            "|CHECK VIDEO ?? ht...|        Negative|\n",
            "|Breaking Story: O...|         Neutral|\n",
            "+--------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH31UFq7Rwdj"
      },
      "source": [
        "#There are no null values in the dataset"
      ],
      "id": "TH31UFq7Rwdj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e511457"
      },
      "source": [
        "(train_set, val_set, test_set) = data.randomSplit([0.98, 0.01, 0.01], seed = 2000)"
      ],
      "id": "6e511457",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3271a73"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"OriginalTweet\", outputCol=\"words\")\n",
        "\n",
        "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
        "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) \n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"target_Sentiment\", outputCol = \"label\")\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])"
      ],
      "id": "f3271a73",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd51f6d2"
      },
      "source": [
        "pipelineFit = pipeline.fit(train_set)\n",
        "train_df = pipelineFit.transform(train_set)"
      ],
      "id": "cd51f6d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13896275",
        "outputId": "4faf4b42-869a-4b28-b8f1-ad02b0a63b89"
      },
      "source": [
        "val_df = pipelineFit.transform(val_set)\n",
        "train_df.show(5)"
      ],
      "id": "13896275",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
            "|       OriginalTweet|target_Sentiment|               words|                  tf|            features|label|\n",
            "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
            "|    Police office...|        Positive|[, , , , police, ...|(65536,[1434,1511...|(65536,[1434,1511...|  0.0|\n",
            "|   I told them th...|        Negative|[, , , i, told, t...|(65536,[1198,5660...|(65536,[1198,5660...|  1.0|\n",
            "|  A revised rail ...|        Positive|[, , a, revised, ...|(65536,[463,1032,...|(65536,[463,1032,...|  0.0|\n",
            "|  Add your favori...|        Positive|[, , add, your, f...|(65536,[19208,203...|(65536,[19208,203...|  0.0|\n",
            "|  COVID 19 UPDATE...|        Positive|[, , covid, 19, u...|(65536,[3856,4629...|(65536,[3856,4629...|  0.0|\n",
            "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "571f899e"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "LR = LogisticRegression(maxIter=100)\n",
        "model = LR.fit(train_df)\n",
        "predictions = model.transform(val_df)"
      ],
      "id": "571f899e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd33ddab"
      },
      "source": [
        "import pandas as pd\n",
        "test_data_sets = {\n",
        "    'OriginalTweet':[\n",
        "        \"i love to go shopping\",\n",
        "        'I hate the Master Chef US, its streaming this Friday on Fox #masterchef',\n",
        "        'i love cooking'\n",
        "    ]\n",
        "}\n",
        "\n",
        "test_result = pd.DataFrame(test_data_sets)\n",
        "\n",
        "test_result = sqlContext.createDataFrame(test_result)"
      ],
      "id": "cd33ddab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7e3a3f2",
        "outputId": "737af990-a697-47fe-ead3-a409d6acd126"
      },
      "source": [
        "test_result.show()"
      ],
      "id": "a7e3a3f2",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|       OriginalTweet|\n",
            "+--------------------+\n",
            "|i love to go shop...|\n",
            "|I hate the Master...|\n",
            "|      i love cooking|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b3baf77"
      },
      "source": [
        "def model_predict(test_):\n",
        "    features = pipelineFit.transform(test_)\n",
        "    preds = model.transform(features)\n",
        "    return preds"
      ],
      "id": "8b3baf77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dea36a75",
        "outputId": "b4b9e726-14e9-425f-af46-def0952b6e00"
      },
      "source": [
        "pred = model_predict(test_result)\n",
        "pred.select('prediction').show()"
      ],
      "id": "dea36a75",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8851e38"
      },
      "source": [
        ""
      ],
      "id": "f8851e38",
      "execution_count": null,
      "outputs": []
    }
  ]
}